{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import difflib\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from src.dataset.util import read_jsonl, write_jsonl\n",
    "\n",
    "\n",
    "RAW_PATH = '../data/raw/'\n",
    "INTERIM_PATH = '../data/interim/'\n",
    "PROCESSED_PATH = '../data/processed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_rr = pd.read_csv(os.path.join(RAW_PATH, 'ResearchRabbit_Export_1701250574.csv'))\n",
    "m_my = pd.read_csv(os.path.join(INTERIM_PATH, 'meta_publications_merged.csv'))\n",
    "\n",
    "### standardize column names\n",
    "# convert to year\n",
    "m_my['year'] = [funk.year for funk in pd.to_datetime(m_my['reconstructed_date'], format='mixed')]\n",
    "# rename columns for merging\n",
    "m_rr = m_rr.rename(columns={'DOI': 'doi', 'Title': 'title', 'Year': 'year'})\n",
    "\n",
    "### split parsing and ocr\n",
    "m_parsing = m_my[m_my['source'] == 'parsing']\n",
    "m_ocr = m_my[m_my['source'] == 'ocr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 271 entries, 0 to 270\n",
      "Data columns (total 8 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   id                  271 non-null    object\n",
      " 1   title               190 non-null    object\n",
      " 2   date                32 non-null     object\n",
      " 3   doi                 75 non-null     object\n",
      " 4   path                271 non-null    object\n",
      " 5   source              271 non-null    object\n",
      " 6   reconstructed_date  271 non-null    object\n",
      " 7   year                271 non-null    int64 \n",
      "dtypes: int64(1), object(7)\n",
      "memory usage: 19.1+ KB\n"
     ]
    }
   ],
   "source": [
    "m_parsing.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### copying ocr files for sofie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reltive_root = Path('..')\n",
    "# destination_root = reltive_root.joinpath('data/interim/ocr_files_orig_structure/')\n",
    "\n",
    "# for i, row in m_ocr.iterrows():\n",
    "#     # find implicated file\n",
    "#     current_path = reltive_root.joinpath(row['path'])\n",
    "#     filename = current_path.name\n",
    "#     # copy directory structure from the UTA Publications\n",
    "#     path_structure = current_path.parent.parts[3:]\n",
    "#     path_structure = Path(*path_structure)\n",
    "#     # create destination directory\n",
    "#     destination_dir = destination_root.joinpath(path_structure)\n",
    "#     destination_dir.mkdir(parents=True, exist_ok=True)\n",
    "#     # copy file\n",
    "#     destination_file_path = destination_dir.joinpath(filename)\n",
    "#     shutil.copy(current_path, destination_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reltive_root = Path('..')\n",
    "# destination_root = reltive_root.joinpath('data/interim/ocr_files_raw/')\n",
    "# destination_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# for i, row in m_ocr.iterrows():\n",
    "#     # find implicated file\n",
    "#     current_path = reltive_root.joinpath(row['path'])\n",
    "#     filename = current_path.name\n",
    "#     # copy file\n",
    "#     destination_file_path = destination_root.joinpath(filename)\n",
    "#     shutil.copy(current_path, destination_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merging title lookup (first round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_1/x3y6hbdn5ljg_g6fr5kj88bs87mgrt/T/ipykernel_37948/1584224269.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  m_parsing['title_in_prs'] = m_parsing['title'].str.lower()\n"
     ]
    }
   ],
   "source": [
    "# lowercase relevant columns\n",
    "m_rr['title_in_rr'] = m_rr['title'].str.lower()\n",
    "m_parsing['title_in_prs'] = m_parsing['title'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 76 entries, 0 to 118\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   title_in_prs  76 non-null     object\n",
      " 1   title_in_rr   76 non-null     object\n",
      " 2   matches       76 non-null     object\n",
      " 3   id            76 non-null     object\n",
      " 4   n_matches     76 non-null     int64 \n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 3.6+ KB\n"
     ]
    }
   ],
   "source": [
    "m_parsing_no_doi = m_parsing[m_parsing['doi'].isna()]\n",
    "m_parsing_no_doi_yes_tit = m_parsing_no_doi[~m_parsing_no_doi['title_in_prs'].isna()]\n",
    "\n",
    "\n",
    "found_pairs = []\n",
    "for i, row in m_parsing_no_doi_yes_tit.iterrows():\n",
    "\n",
    "    close_match = difflib.get_close_matches(\n",
    "        row['title_in_prs'], \n",
    "        m_rr[\"title_in_rr\"].to_list(),\n",
    "        cutoff=0.8\n",
    "        )\n",
    "    \n",
    "    if close_match == []:\n",
    "        n_matches = 0\n",
    "        selected_title = None\n",
    "        close_match = None\n",
    "    else: \n",
    "        n_matches = len(close_match)\n",
    "        selected_title = close_match[0]\n",
    "    \n",
    "    found_pairs.append({\n",
    "        'title_in_prs': row['title_in_prs'],\n",
    "        'title_in_rr': selected_title,\n",
    "        'matches': close_match,\n",
    "        'id': row['id'],\n",
    "        'n_matches': n_matches,\n",
    "    })\n",
    "\n",
    "found_pairs = pd.DataFrame(found_pairs)\n",
    "useful_found_pairs = found_pairs.query('n_matches > 0')\n",
    "\n",
    "useful_found_pairs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 119 entries, 0 to 118\n",
      "Data columns (total 19 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   id                  119 non-null    object \n",
      " 1   title_prs           119 non-null    object \n",
      " 2   date                7 non-null      object \n",
      " 3   path                119 non-null    object \n",
      " 4   source              119 non-null    object \n",
      " 5   reconstructed_date  119 non-null    object \n",
      " 6   year_prs            119 non-null    int64  \n",
      " 7   title_in_prs        119 non-null    object \n",
      " 8   title_in_rr         76 non-null     object \n",
      " 9   matches             76 non-null     object \n",
      " 10  n_matches           76 non-null     float64\n",
      " 11  doi                 65 non-null     object \n",
      " 12  PMID                42 non-null     float64\n",
      " 13  arXiv ID            0 non-null      float64\n",
      " 14  title_rr            76 non-null     object \n",
      " 15  Abstract            61 non-null     object \n",
      " 16  Authors             76 non-null     object \n",
      " 17  Journal             63 non-null     object \n",
      " 18  year_rr             76 non-null     float64\n",
      "dtypes: float64(4), int64(1), object(14)\n",
      "memory usage: 17.8+ KB\n"
     ]
    }
   ],
   "source": [
    "m_parsing_aug1 = pd.merge(\n",
    "    m_parsing_no_doi_yes_tit.drop(columns=['doi']),\n",
    "    useful_found_pairs.drop(columns=['title_in_prs']),\n",
    "    on='id', how='left'\n",
    "    )\n",
    "\n",
    "m_parsing_aug1 = pd.merge(\n",
    "    m_parsing_aug1,\n",
    "    m_rr,\n",
    "    on='title_in_rr', how='left',\n",
    "    suffixes=('_prs', '_rr')\n",
    "    )\n",
    "\n",
    "m_parsing_aug1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merging based on doi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 75 entries, 0 to 74\n",
      "Data columns (total 17 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   id                  75 non-null     object \n",
      " 1   title_prs           71 non-null     object \n",
      " 2   date                24 non-null     object \n",
      " 3   doi                 75 non-null     object \n",
      " 4   path                75 non-null     object \n",
      " 5   source              75 non-null     object \n",
      " 6   reconstructed_date  75 non-null     object \n",
      " 7   year_prs            75 non-null     int64  \n",
      " 8   title_in_prs        71 non-null     object \n",
      " 9   PMID                57 non-null     float64\n",
      " 10  arXiv ID            0 non-null      float64\n",
      " 11  title_rr            61 non-null     object \n",
      " 12  Abstract            59 non-null     object \n",
      " 13  Authors             61 non-null     object \n",
      " 14  Journal             59 non-null     object \n",
      " 15  year_rr             60 non-null     float64\n",
      " 16  title_in_rr         61 non-null     object \n",
      "dtypes: float64(3), int64(1), object(13)\n",
      "memory usage: 10.1+ KB\n"
     ]
    }
   ],
   "source": [
    "m_parsing_yes_doi = m_parsing[~m_parsing['doi'].isna()]\n",
    "\n",
    "m_parsing_aug2 = pd.merge(m_parsing_yes_doi, m_rr, on='doi', how='left', suffixes=('_prs', '_rr'))\n",
    "m_parsing_aug2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merging the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 194 entries, 0 to 193\n",
      "Data columns (total 16 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   id                  194 non-null    object \n",
      " 1   title_prs           190 non-null    object \n",
      " 2   date                31 non-null     object \n",
      " 3   path                194 non-null    object \n",
      " 4   source              194 non-null    object \n",
      " 5   reconstructed_date  194 non-null    object \n",
      " 6   year_prs            194 non-null    int64  \n",
      " 7   title_in_prs        190 non-null    object \n",
      " 8   title_in_rr         137 non-null    object \n",
      " 9   doi                 140 non-null    object \n",
      " 10  PMID                99 non-null     float64\n",
      " 11  title_rr            137 non-null    object \n",
      " 12  Abstract            120 non-null    object \n",
      " 13  Authors             137 non-null    object \n",
      " 14  Journal             122 non-null    object \n",
      " 15  year_rr             136 non-null    float64\n",
      "dtypes: float64(2), int64(1), object(13)\n",
      "memory usage: 24.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# join the partially augumented dfs\n",
    "m_parsing_aug_complete = pd.concat([m_parsing_aug1, m_parsing_aug2], ignore_index=True)\n",
    "# drop garbage columns\n",
    "m_parsing_aug_complete = m_parsing_aug_complete.drop(columns=['matches', 'n_matches', 'arXiv ID'])\n",
    "m_parsing_aug_complete.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert m_parsing_aug_complete['id'].nunique() == len(m_parsing_aug_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 77 entries, 0 to 257\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   id                  77 non-null     object\n",
      " 1   date                1 non-null      object\n",
      " 2   path                77 non-null     object\n",
      " 3   source              77 non-null     object\n",
      " 4   reconstructed_date  77 non-null     object\n",
      " 5   year_prs            77 non-null     int64 \n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 4.2+ KB\n"
     ]
    }
   ],
   "source": [
    "non_overlap = set(m_parsing['id'].tolist()) - set(m_parsing_aug_complete['id'].tolist())\n",
    "assert len(m_parsing) - len(m_parsing_aug_complete) == len(non_overlap)\n",
    "\n",
    "m_parsing_missing = m_parsing[m_parsing['id'].isin(non_overlap)]\n",
    "m_parsing_missing = (m_parsing_missing\n",
    "                     .drop(columns=['title', 'doi', 'title_in_prs'])\n",
    "                     .rename(columns={'year': 'year_prs'})\n",
    "                     )\n",
    "\n",
    "m_parsing_missing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 271 entries, 0 to 270\n",
      "Data columns (total 16 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   id                  271 non-null    object \n",
      " 1   title_prs           190 non-null    object \n",
      " 2   date                32 non-null     object \n",
      " 3   path                271 non-null    object \n",
      " 4   source              271 non-null    object \n",
      " 5   reconstructed_date  271 non-null    object \n",
      " 6   year_prs            271 non-null    int64  \n",
      " 7   title_in_prs        190 non-null    object \n",
      " 8   title_in_rr         137 non-null    object \n",
      " 9   doi                 140 non-null    object \n",
      " 10  PMID                99 non-null     float64\n",
      " 11  title_rr            137 non-null    object \n",
      " 12  Abstract            120 non-null    object \n",
      " 13  Authors             137 non-null    object \n",
      " 14  Journal             122 non-null    object \n",
      " 15  year_rr             136 non-null    float64\n",
      "dtypes: float64(2), int64(1), object(13)\n",
      "memory usage: 34.0+ KB\n"
     ]
    }
   ],
   "source": [
    "m_parsing_ = pd.concat([m_parsing_aug_complete, m_parsing_missing], ignore_index=True)\n",
    "m_parsing_ = m_parsing_.reset_index(drop=True)\n",
    "m_parsing_.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 271 entries, 0 to 270\n",
      "Data columns (total 18 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   id                  271 non-null    object \n",
      " 1   title_prs           190 non-null    object \n",
      " 2   date                32 non-null     object \n",
      " 3   path                271 non-null    object \n",
      " 4   source              271 non-null    object \n",
      " 5   reconstructed_date  271 non-null    object \n",
      " 6   year_prs            271 non-null    int64  \n",
      " 7   title_in_prs        190 non-null    object \n",
      " 8   title_in_rr         137 non-null    object \n",
      " 9   doi                 140 non-null    object \n",
      " 10  PMID                99 non-null     float64\n",
      " 11  title_rr            137 non-null    object \n",
      " 12  Abstract            120 non-null    object \n",
      " 13  Authors             137 non-null    object \n",
      " 14  Journal             122 non-null    object \n",
      " 15  year_rr             136 non-null    float64\n",
      " 16  year                271 non-null    object \n",
      " 17  title               192 non-null    object \n",
      "dtypes: float64(2), int64(1), object(15)\n",
      "memory usage: 38.2+ KB\n"
     ]
    }
   ],
   "source": [
    "m_parsing_['year'] = None\n",
    "m_parsing_['title'] = None\n",
    "\n",
    "for i, row in m_parsing_.iterrows():\n",
    "    # year\n",
    "    if pd.isna(row['year_rr']):\n",
    "        m_parsing_.loc[i, 'year'] = row['year_prs']\n",
    "    else:\n",
    "        m_parsing_.loc[i, 'year'] = row['year_rr']\n",
    "\n",
    "    # title\n",
    "    if pd.isna(row['title_rr']):\n",
    "        m_parsing_.loc[i, 'title'] = row['title_prs']\n",
    "    else:\n",
    "        m_parsing_.loc[i, 'title'] = row['title_rr']\n",
    "\n",
    "m_parsing_.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 271 entries, 0 to 270\n",
      "Data columns (total 10 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   id        271 non-null    object \n",
      " 1   path      271 non-null    object \n",
      " 2   source    271 non-null    object \n",
      " 3   doi       140 non-null    object \n",
      " 4   PMID      99 non-null     float64\n",
      " 5   Abstract  120 non-null    object \n",
      " 6   Authors   137 non-null    object \n",
      " 7   Journal   122 non-null    object \n",
      " 8   year      271 non-null    object \n",
      " 9   title     192 non-null    object \n",
      "dtypes: float64(1), object(9)\n",
      "memory usage: 21.3+ KB\n"
     ]
    }
   ],
   "source": [
    "(m_parsing_\n",
    "    .drop(columns=['title_in_rr', 'title_in_prs', 'year_prs', 'year_rr', 'title_prs', 'title_rr'])\n",
    "    .drop(columns=['date', 'reconstructed_date'])\n",
    ").info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save m_parsing_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### it worked\n",
    "\n",
    "There are 272 good documents (2 are broken & can't be openned).  \n",
    "Out of those, 271 were successfully parsed with `scipdf`.\n",
    "\n",
    "Now we have full metadata specification for 140 documents & valid year for all the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "qual = pd.read_csv(os.path.join(PROCESSED_PATH, 'meta_publications_quality.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "passed_quality_check\n",
       "False     68\n",
       "True     322\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove rows with nan in 'text' column\n",
    "# tp for text present\n",
    "qual_tp = qual.dropna(subset=['text'])\n",
    "qual_tp.groupby('passed_quality_check').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Recent studies on mentalizing have shown that ...\n",
       "1      Introduction\\nTheory of Mind is defined as the...\n",
       "51     \\nIn the same way that a literal tool such as ...\n",
       "71     Introduction\\nWhen a child or adult starts to ...\n",
       "73     \\nRecent research has confirmed that dyslexia ...\n",
       "                             ...                        \n",
       "515    \\n|\\n\\n \\n\\n \\n\\nCopniion, 50 (198) 115-122\\n(...\n",
       "523    \\n \\n\\n \\n\\nDyslexia: can we have a shared\\nth...\n",
       "525    \\nCHAPTER 13,\\n\\nCausal Modeling: A Structural...\n",
       "529    \\n[SPECIFIC SPELLING PROBLENS\\n\\nee Festn\\n\\nI...\n",
       "537    \\nKlaus B.Giinther/ Hartmut Giinther (Hg.)\\nSc...\n",
       "Name: text, Length: 68, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qual_tp.query('passed_quality_check == False')['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 390 entries, 0 to 541\n",
      "Data columns (total 79 columns):\n",
      " #   Column                                  Non-Null Count  Dtype  \n",
      "---  ------                                  --------------  -----  \n",
      " 0   Unnamed: 0                              390 non-null    int64  \n",
      " 1   pub_id                                  390 non-null    object \n",
      " 2   title                                   276 non-null    object \n",
      " 3   date                                    51 non-null     object \n",
      " 4   doi                                     115 non-null    object \n",
      " 5   path                                    390 non-null    object \n",
      " 6   source                                  390 non-null    object \n",
      " 7   reconstructed_date                      390 non-null    object \n",
      " 8   lang                                    390 non-null    object \n",
      " 9   text                                    390 non-null    object \n",
      " 10  flesch_reading_ease                     390 non-null    float64\n",
      " 11  flesch_kincaid_grade                    390 non-null    float64\n",
      " 12  smog                                    382 non-null    float64\n",
      " 13  gunning_fog                             390 non-null    float64\n",
      " 14  automated_readability_index             390 non-null    float64\n",
      " 15  coleman_liau_index                      390 non-null    float64\n",
      " 16  lix                                     390 non-null    float64\n",
      " 17  rix                                     390 non-null    float64\n",
      " 18  passed_quality_check                    390 non-null    bool   \n",
      " 19  n_stop_words                            390 non-null    float64\n",
      " 20  alpha_ratio                             390 non-null    float64\n",
      " 21  mean_word_length                        390 non-null    float64\n",
      " 22  doc_length                              390 non-null    float64\n",
      " 23  symbol_to_word_ratio_#                  390 non-null    float64\n",
      " 24  proportion_ellipsis                     390 non-null    float64\n",
      " 25  proportion_bullet_points                390 non-null    float64\n",
      " 26  contains_lorem ipsum                    390 non-null    float64\n",
      " 27  duplicate_line_chr_fraction             390 non-null    float64\n",
      " 28  duplicate_paragraph_chr_fraction        390 non-null    float64\n",
      " 29  duplicate_ngram_chr_fraction_5          390 non-null    float64\n",
      " 30  duplicate_ngram_chr_fraction_6          390 non-null    float64\n",
      " 31  duplicate_ngram_chr_fraction_7          390 non-null    float64\n",
      " 32  duplicate_ngram_chr_fraction_8          390 non-null    float64\n",
      " 33  duplicate_ngram_chr_fraction_9          390 non-null    float64\n",
      " 34  duplicate_ngram_chr_fraction_10         390 non-null    float64\n",
      " 35  top_ngram_chr_fraction_2                390 non-null    float64\n",
      " 36  top_ngram_chr_fraction_3                390 non-null    float64\n",
      " 37  top_ngram_chr_fraction_4                390 non-null    float64\n",
      " 38  oov_ratio                               390 non-null    float64\n",
      " 39  token_length_mean                       390 non-null    float64\n",
      " 40  token_length_median                     390 non-null    float64\n",
      " 41  token_length_std                        390 non-null    float64\n",
      " 42  sentence_length_mean                    390 non-null    float64\n",
      " 43  sentence_length_median                  390 non-null    float64\n",
      " 44  sentence_length_std                     390 non-null    float64\n",
      " 45  syllables_per_token_mean                390 non-null    float64\n",
      " 46  syllables_per_token_median              390 non-null    float64\n",
      " 47  syllables_per_token_std                 390 non-null    float64\n",
      " 48  n_tokens                                390 non-null    int64  \n",
      " 49  n_unique_tokens                         390 non-null    int64  \n",
      " 50  proportion_unique_tokens                390 non-null    float64\n",
      " 51  n_characters                            390 non-null    int64  \n",
      " 52  n_sentences                             390 non-null    int64  \n",
      " 53  entropy                                 390 non-null    float64\n",
      " 54  perplexity                              390 non-null    float64\n",
      " 55  per_word_perplexity                     390 non-null    float64\n",
      " 56  first_order_coherence                   386 non-null    float64\n",
      " 57  second_order_coherence                  382 non-null    float64\n",
      " 58  dependency_distance_mean                390 non-null    float64\n",
      " 59  dependency_distance_std                 390 non-null    float64\n",
      " 60  prop_adjacent_dependency_relation_mean  390 non-null    float64\n",
      " 61  prop_adjacent_dependency_relation_std   390 non-null    float64\n",
      " 62  pos_prop_ADJ                            390 non-null    float64\n",
      " 63  pos_prop_ADP                            390 non-null    float64\n",
      " 64  pos_prop_ADV                            390 non-null    float64\n",
      " 65  pos_prop_AUX                            390 non-null    float64\n",
      " 66  pos_prop_CCONJ                          390 non-null    float64\n",
      " 67  pos_prop_DET                            390 non-null    float64\n",
      " 68  pos_prop_INTJ                           390 non-null    float64\n",
      " 69  pos_prop_NOUN                           390 non-null    float64\n",
      " 70  pos_prop_NUM                            390 non-null    float64\n",
      " 71  pos_prop_PART                           390 non-null    float64\n",
      " 72  pos_prop_PRON                           390 non-null    float64\n",
      " 73  pos_prop_PROPN                          390 non-null    float64\n",
      " 74  pos_prop_PUNCT                          390 non-null    float64\n",
      " 75  pos_prop_SCONJ                          390 non-null    float64\n",
      " 76  pos_prop_SYM                            390 non-null    float64\n",
      " 77  pos_prop_VERB                           390 non-null    float64\n",
      " 78  pos_prop_X                              390 non-null    float64\n",
      "dtypes: bool(1), float64(64), int64(5), object(9)\n",
      "memory usage: 241.1+ KB\n"
     ]
    }
   ],
   "source": [
    "qual_tp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
