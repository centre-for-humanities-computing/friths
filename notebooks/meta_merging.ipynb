{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import difflib\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from src.dataset.util import read_jsonl, write_jsonl\n",
    "\n",
    "\n",
    "RAW_PATH = '../data/raw/'\n",
    "INTERIM_PATH = '../data/interim/'\n",
    "PROCESSED_PATH = '../data/processed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_rr = pd.read_csv(os.path.join(RAW_PATH, 'ResearchRabbit_Export_1701250574.csv'))\n",
    "m_my = pd.read_csv(os.path.join(INTERIM_PATH, 'meta_publications_merged.csv'))\n",
    "\n",
    "### standardize column names\n",
    "# convert to year\n",
    "m_my['year'] = [funk.year for funk in pd.to_datetime(m_my['reconstructed_date'], format='mixed')]\n",
    "# rename columns for merging\n",
    "m_rr = m_rr.rename(columns={'DOI': 'doi', 'Title': 'title', 'Year': 'year'})\n",
    "\n",
    "### split parsing and ocr\n",
    "m_parsing = m_my[m_my['source'] == 'parsing']\n",
    "m_ocr = m_my[m_my['source'] == 'ocr']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### copying ocr files for sofie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reltive_root = Path('..')\n",
    "# destination_root = reltive_root.joinpath('data/interim/ocr_files_orig_structure/')\n",
    "\n",
    "# for i, row in m_ocr.iterrows():\n",
    "#     # find implicated file\n",
    "#     current_path = reltive_root.joinpath(row['path'])\n",
    "#     filename = current_path.name\n",
    "#     # copy directory structure from the UTA Publications\n",
    "#     path_structure = current_path.parent.parts[3:]\n",
    "#     path_structure = Path(*path_structure)\n",
    "#     # create destination directory\n",
    "#     destination_dir = destination_root.joinpath(path_structure)\n",
    "#     destination_dir.mkdir(parents=True, exist_ok=True)\n",
    "#     # copy file\n",
    "#     destination_file_path = destination_dir.joinpath(filename)\n",
    "#     shutil.copy(current_path, destination_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reltive_root = Path('..')\n",
    "# destination_root = reltive_root.joinpath('data/interim/ocr_files_raw/')\n",
    "# destination_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# for i, row in m_ocr.iterrows():\n",
    "#     # find implicated file\n",
    "#     current_path = reltive_root.joinpath(row['path'])\n",
    "#     filename = current_path.name\n",
    "#     # copy file\n",
    "#     destination_file_path = destination_root.joinpath(filename)\n",
    "#     shutil.copy(current_path, destination_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/raw/UTA publications/UF papers 2011-2013 copy/25 years for APS 2013.pdf'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_my.loc[20, 'path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mapping Mentalising in the Brain']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difflib.get_close_matches(\n",
    "    \"mapping mentalising in the brain\", \n",
    "    # m_rr[\"Title\"].str.lower().to_list()\n",
    "    m_rr[\"Title\"].to_list()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DOI</th>\n",
       "      <th>PMID</th>\n",
       "      <th>arXiv ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Journal</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>10.1007/978-3-030-51890-5_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mapping Mentalising in the Brain</td>\n",
       "      <td>This is a short history of mentalising researc...</td>\n",
       "      <td>Chris D. Frith,Uta Frith</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2021.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            DOI  PMID  arXiv ID  \\\n",
       "47  10.1007/978-3-030-51890-5_2   NaN       NaN   \n",
       "\n",
       "                               Title  \\\n",
       "47  Mapping Mentalising in the Brain   \n",
       "\n",
       "                                             Abstract  \\\n",
       "47  This is a short history of mentalising researc...   \n",
       "\n",
       "                     Authors Journal    Year  \n",
       "47  Chris D. Frith,Uta Frith     NaN  2021.0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_rr.query('Title == \"Mapping Mentalising in the Brain\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lowercase relevant columns\n",
    "# m_rr['title_l'] = m_rr['Title'].str.lower() \n",
    "# m_my['title_l'] = m_my['title'].str.lower()\n",
    "# m_my['authors_l'] = m_my['authors'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "### merge on doi first\n",
    "# convert to year\n",
    "m_my['year'] = [funk.year for funk in pd.to_datetime(m_my['reconstructed_date'], format='mixed')]\n",
    "# rename columns for merging\n",
    "m_rr = m_rr.rename(columns={'DOI': 'doi', 'Title': 'title', 'Year': 'year'})\n",
    "m = pd.merge(m_my, m_rr, how='inner', on='doi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_rr_full_doi = m_rr.dropna(subset=['doi'])\n",
    "\n",
    "m = pd.merge(m_my, m_rr_full_doi, how='left', on='doi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merging title lookup (first round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_1/x3y6hbdn5ljg_g6fr5kj88bs87mgrt/T/ipykernel_96439/1584224269.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  m_parsing['title_in_prs'] = m_parsing['title'].str.lower()\n"
     ]
    }
   ],
   "source": [
    "# lowercase relevant columns\n",
    "m_rr['title_in_rr'] = m_rr['title'].str.lower()\n",
    "m_parsing['title_in_prs'] = m_parsing['title'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_parsing_no_doi = m_parsing[m_parsing['doi'].isna()]\n",
    "m_parsing_no_doi_yes_tit = m_parsing_no_doi[~m_parsing_no_doi['title_in_prs'].isna()]\n",
    "\n",
    "\n",
    "found_pairs = []\n",
    "for i, row in m_parsing_no_doi_yes_tit.iterrows():\n",
    "\n",
    "    close_match = difflib.get_close_matches(\n",
    "        row['title_in_prs'], \n",
    "        m_rr[\"title_in_rr\"].to_list(),\n",
    "        cutoff=0.8\n",
    "        )\n",
    "    \n",
    "    if close_match == []:\n",
    "        n_matches = 0\n",
    "        selected_title = None\n",
    "        close_match = None\n",
    "    else: \n",
    "        n_matches = len(close_match)\n",
    "        selected_title = close_match[0]\n",
    "    \n",
    "    found_pairs.append({\n",
    "        'title_in_prs': row['title_in_prs'],\n",
    "        'title_in_rr': selected_title,\n",
    "        'matches': close_match,\n",
    "        'id': row['id'],\n",
    "        'n_matches': n_matches,\n",
    "    })\n",
    "\n",
    "found_pairs = pd.DataFrame(found_pairs)\n",
    "useful_found_pairs = found_pairs.query('n_matches > 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 66 entries, 0 to 65\n",
      "Data columns (total 19 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   id                  66 non-null     object \n",
      " 1   title_prs           66 non-null     object \n",
      " 2   date                6 non-null      object \n",
      " 3   path                66 non-null     object \n",
      " 4   source              66 non-null     object \n",
      " 5   reconstructed_date  66 non-null     object \n",
      " 6   year_prs            66 non-null     int64  \n",
      " 7   title_in_prs        66 non-null     object \n",
      " 8   title_in_rr         48 non-null     object \n",
      " 9   matches             48 non-null     object \n",
      " 10  n_matches           48 non-null     float64\n",
      " 11  doi                 41 non-null     object \n",
      " 12  PMID                28 non-null     float64\n",
      " 13  arXiv ID            0 non-null      float64\n",
      " 14  title_rr            48 non-null     object \n",
      " 15  Abstract            40 non-null     object \n",
      " 16  Authors             48 non-null     object \n",
      " 17  Journal             40 non-null     object \n",
      " 18  year_rr             48 non-null     float64\n",
      "dtypes: float64(4), int64(1), object(14)\n",
      "memory usage: 9.9+ KB\n"
     ]
    }
   ],
   "source": [
    "m_parsing_aug1 = pd.merge(\n",
    "    m_parsing_no_doi_yes_tit.drop(columns=['doi']),\n",
    "    useful_found_pairs.drop(columns=['title_in_prs']),\n",
    "    on='id', how='left'\n",
    "    )\n",
    "\n",
    "m_parsing_aug1 = pd.merge(\n",
    "    m_parsing_aug1,\n",
    "    m_rr,\n",
    "    on='title_in_rr', how='left',\n",
    "    suffixes=('_prs', '_rr')\n",
    "    )\n",
    "\n",
    "m_parsing_aug1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merging based on doi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 75 entries, 0 to 74\n",
      "Data columns (total 17 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   id                  75 non-null     object \n",
      " 1   title_prs           71 non-null     object \n",
      " 2   date                24 non-null     object \n",
      " 3   doi                 75 non-null     object \n",
      " 4   path                75 non-null     object \n",
      " 5   source              75 non-null     object \n",
      " 6   reconstructed_date  75 non-null     object \n",
      " 7   year_prs            75 non-null     int64  \n",
      " 8   title_in_prs        71 non-null     object \n",
      " 9   PMID                57 non-null     float64\n",
      " 10  arXiv ID            0 non-null      float64\n",
      " 11  title_rr            61 non-null     object \n",
      " 12  Abstract            59 non-null     object \n",
      " 13  Authors             61 non-null     object \n",
      " 14  Journal             59 non-null     object \n",
      " 15  year_rr             60 non-null     float64\n",
      " 16  title_in_rr         61 non-null     object \n",
      "dtypes: float64(3), int64(1), object(13)\n",
      "memory usage: 10.1+ KB\n"
     ]
    }
   ],
   "source": [
    "m_parsing_yes_doi = m_parsing[~m_parsing['doi'].isna()]\n",
    "\n",
    "m_parsing_aug2 = pd.merge(m_parsing_yes_doi, m_rr, on='doi', how='left', suffixes=('_prs', '_rr'))\n",
    "m_parsing_aug2.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merging the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 141 entries, 0 to 140\n",
      "Data columns (total 16 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   id                  141 non-null    object \n",
      " 1   title_prs           137 non-null    object \n",
      " 2   date                30 non-null     object \n",
      " 3   path                141 non-null    object \n",
      " 4   source              141 non-null    object \n",
      " 5   reconstructed_date  141 non-null    object \n",
      " 6   year_prs            141 non-null    int64  \n",
      " 7   title_in_prs        137 non-null    object \n",
      " 8   title_in_rr         109 non-null    object \n",
      " 9   doi                 116 non-null    object \n",
      " 10  PMID                85 non-null     float64\n",
      " 11  title_rr            109 non-null    object \n",
      " 12  Abstract            99 non-null     object \n",
      " 13  Authors             109 non-null    object \n",
      " 14  Journal             99 non-null     object \n",
      " 15  year_rr             108 non-null    float64\n",
      "dtypes: float64(2), int64(1), object(13)\n",
      "memory usage: 17.8+ KB\n"
     ]
    }
   ],
   "source": [
    "# join the partially augumented dfs\n",
    "m_parsing_aug_complete = pd.concat([m_parsing_aug1, m_parsing_aug2], ignore_index=True)\n",
    "# drop garbage columns\n",
    "m_parsing_aug_complete = m_parsing_aug_complete.drop(columns=['matches', 'n_matches', 'arXiv ID'])\n",
    "m_parsing_aug_complete.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert m_parsing_aug_complete['id'].nunique() == len(m_parsing_aug_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 13 entries, 6 to 125\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   id                  13 non-null     object\n",
      " 1   date                1 non-null      object\n",
      " 2   path                13 non-null     object\n",
      " 3   source              13 non-null     object\n",
      " 4   reconstructed_date  13 non-null     object\n",
      " 5   year_prs            13 non-null     int64 \n",
      "dtypes: int64(1), object(5)\n",
      "memory usage: 728.0+ bytes\n"
     ]
    }
   ],
   "source": [
    "non_overlap = set(m_parsing['id'].tolist()) - set(m_parsing_aug_complete['id'].tolist())\n",
    "assert len(m_parsing) - len(m_parsing_aug_complete) == len(non_overlap)\n",
    "\n",
    "m_parsing_missing = m_parsing[m_parsing['id'].isin(non_overlap)]\n",
    "m_parsing_missing = (m_parsing_missing\n",
    "                     .drop(columns=['title', 'doi', 'title_in_prs'])\n",
    "                     .rename(columns={'year': 'year_prs'})\n",
    "                     )\n",
    "\n",
    "m_parsing_missing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 154 entries, 0 to 153\n",
      "Data columns (total 16 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   id                  154 non-null    object \n",
      " 1   title_prs           137 non-null    object \n",
      " 2   date                31 non-null     object \n",
      " 3   path                154 non-null    object \n",
      " 4   source              154 non-null    object \n",
      " 5   reconstructed_date  154 non-null    object \n",
      " 6   year_prs            154 non-null    int64  \n",
      " 7   title_in_prs        137 non-null    object \n",
      " 8   title_in_rr         109 non-null    object \n",
      " 9   doi                 116 non-null    object \n",
      " 10  PMID                85 non-null     float64\n",
      " 11  title_rr            109 non-null    object \n",
      " 12  Abstract            99 non-null     object \n",
      " 13  Authors             109 non-null    object \n",
      " 14  Journal             99 non-null     object \n",
      " 15  year_rr             108 non-null    float64\n",
      "dtypes: float64(2), int64(1), object(13)\n",
      "memory usage: 19.4+ KB\n"
     ]
    }
   ],
   "source": [
    "m_parsing_ = pd.concat([m_parsing_aug_complete, m_parsing_missing], ignore_index=True)\n",
    "m_parsing_ = m_parsing_.reset_index(drop=True)\n",
    "m_parsing_.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 154 entries, 0 to 153\n",
      "Data columns (total 18 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   id                  154 non-null    object \n",
      " 1   title_prs           137 non-null    object \n",
      " 2   date                31 non-null     object \n",
      " 3   path                154 non-null    object \n",
      " 4   source              154 non-null    object \n",
      " 5   reconstructed_date  154 non-null    object \n",
      " 6   year_prs            154 non-null    int64  \n",
      " 7   title_in_prs        137 non-null    object \n",
      " 8   title_in_rr         109 non-null    object \n",
      " 9   doi                 116 non-null    object \n",
      " 10  PMID                85 non-null     float64\n",
      " 11  title_rr            109 non-null    object \n",
      " 12  Abstract            99 non-null     object \n",
      " 13  Authors             109 non-null    object \n",
      " 14  Journal             99 non-null     object \n",
      " 15  year_rr             108 non-null    float64\n",
      " 16  year                154 non-null    object \n",
      " 17  title               139 non-null    object \n",
      "dtypes: float64(2), int64(1), object(15)\n",
      "memory usage: 21.8+ KB\n"
     ]
    }
   ],
   "source": [
    "m_parsing_['year'] = None\n",
    "m_parsing_['title'] = None\n",
    "\n",
    "for i, row in m_parsing_.iterrows():\n",
    "    # year\n",
    "    if pd.isna(row['year_rr']):\n",
    "        m_parsing_.loc[i, 'year'] = row['year_prs']\n",
    "    else:\n",
    "        m_parsing_.loc[i, 'year'] = row['year_rr']\n",
    "\n",
    "    # title\n",
    "    if pd.isna(row['title_rr']):\n",
    "        m_parsing_.loc[i, 'title'] = row['title_prs']\n",
    "    else:\n",
    "        m_parsing_.loc[i, 'title'] = row['title_rr']\n",
    "\n",
    "m_parsing_.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 154 entries, 0 to 153\n",
      "Data columns (total 10 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   id        154 non-null    object \n",
      " 1   path      154 non-null    object \n",
      " 2   source    154 non-null    object \n",
      " 3   doi       116 non-null    object \n",
      " 4   PMID      85 non-null     float64\n",
      " 5   Abstract  99 non-null     object \n",
      " 6   Authors   109 non-null    object \n",
      " 7   Journal   99 non-null     object \n",
      " 8   year      154 non-null    object \n",
      " 9   title     139 non-null    object \n",
      "dtypes: float64(1), object(9)\n",
      "memory usage: 12.2+ KB\n"
     ]
    }
   ],
   "source": [
    "(m_parsing_\n",
    "    .drop(columns=['title_in_rr', 'title_in_prs', 'year_prs', 'year_rr', 'title_prs', 'title_rr'])\n",
    "    .drop(columns=['date', 'reconstructed_date'])\n",
    ").info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save m_parsing_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
